{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import hstack\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('filter_book.json') as f:\n",
    "    whole_data = [json.loads(d) for d in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asin': ' ',\n",
       " 'authors': [{'author_id': '5321960', 'role': ''}],\n",
       " 'average_rating': '4.05',\n",
       " 'book_id': '17339335',\n",
       " 'country_code': 'US',\n",
       " 'cover': 'Knight Avenged',\n",
       " 'description': \"<b>Alone in a world on the brink of war...two unlikely allies will discover a love greater than time.</b><br /><br />Exiled from her home, powerful oracle Cosmina Cordei holds the key to uniting those protecting mankind from evil. But just as she makes her way into the holy city to perform an ancient rite, the enemy closes in for the kill...<br /><br />Drawn by a destiny he won't accept, elite assassin Henrik Lazar detests the mystical curse handed down by his mother. But when the sorcery in his blood is activated and past pain comes back to haunt him, his new abilities come into play and he must learn to control them.<br /><br />Rescued by Henrik in the heat of battle, Cosmina must decide whether to trust the assassin who loathes the goddess she serves or face certain death on her own. Forced into an untenable position, Henrik is left with a terrible choice--protect the magical Order he despises, or deny destiny and lose the woman he loves forever.\",\n",
       " 'edition_information': ' ',\n",
       " 'format': 'Paperback',\n",
       " 'genre': {'fantasy, paranormal': 74,\n",
       "  'fiction': 3,\n",
       "  'history, historical fiction, biography': 13,\n",
       "  'romance': 37},\n",
       " 'image_url': 'https://images.gr-assets.com/books/1398345575m/17339335.jpg',\n",
       " 'is_ebook': 'false',\n",
       " 'isbn': '1612187102',\n",
       " 'isbn13': '9781612187105',\n",
       " 'kindle_asin': 'B008H5VWVG',\n",
       " 'language_code': 'eng',\n",
       " 'link': 'https://www.goodreads.com/book/show/17339335-knight-avenged',\n",
       " 'num_pages': '412',\n",
       " 'popular_shelves': [{'count': '1173', 'name': 'to-read'},\n",
       "  {'count': '126', 'name': 'currently-reading'},\n",
       "  {'count': '24', 'name': 'fantasy'},\n",
       "  {'count': '18', 'name': 'paranormal-romance'},\n",
       "  {'count': '17', 'name': 'paranormal'},\n",
       "  {'count': '13', 'name': 'coreene-callahan'},\n",
       "  {'count': '12', 'name': 'kindle'},\n",
       "  {'count': '11', 'name': 'kindle-unlimited'},\n",
       "  {'count': '11', 'name': 'romance'},\n",
       "  {'count': '10', 'name': 'magic'},\n",
       "  {'count': '8', 'name': 'dragons'},\n",
       "  {'count': '8', 'name': 'series'},\n",
       "  {'count': '6', 'name': 'ebook'},\n",
       "  {'count': '5', 'name': 'audiobook'},\n",
       "  {'count': '5', 'name': 'audible'},\n",
       "  {'count': '5', 'name': 'shifters'},\n",
       "  {'count': '5', 'name': 'witches'},\n",
       "  {'count': '5', 'name': 'historical'},\n",
       "  {'count': '4', 'name': 'favorites'},\n",
       "  {'count': '4', 'name': 'books-i-own'},\n",
       "  {'count': '4', 'name': 'shapeshifters'},\n",
       "  {'count': '4', 'name': 'historical-romance'},\n",
       "  {'count': '4', 'name': 'audiobooks'},\n",
       "  {'count': '3', 'name': 'fiction'},\n",
       "  {'count': '3', 'name': 'to-read-paranormal'},\n",
       "  {'count': '3', 'name': 'medieval'},\n",
       "  {'count': '3', 'name': 'owned'},\n",
       "  {'count': '3', 'name': 'historical-fantasy'},\n",
       "  {'count': '3', 'name': 'action'},\n",
       "  {'count': '3', 'name': 'adult'},\n",
       "  {'count': '3', 'name': 'audio'},\n",
       "  {'count': '3', 'name': 'urban-fantasy'},\n",
       "  {'count': '3', 'name': 'alpha-male'},\n",
       "  {'count': '3', 'name': 'demons'},\n",
       "  {'count': '3', 'name': 'first-reads'},\n",
       "  {'count': '3', 'name': 'ebooks'},\n",
       "  {'count': '3', 'name': 'read-in-2014'},\n",
       "  {'count': '2', 'name': 'amazon'},\n",
       "  {'count': '2', 'name': 'maybe'},\n",
       "  {'count': '2', 'name': 'circle-of-seven'},\n",
       "  {'count': '2', 'name': 'owned-to-read'},\n",
       "  {'count': '2', 'name': 'assassin'},\n",
       "  {'count': '2', 'name': 'owned-books'},\n",
       "  {'count': '2', 'name': 'gods'},\n",
       "  {'count': '2', 'name': 'wish-list'},\n",
       "  {'count': '2', 'name': 'erotica'},\n",
       "  {'count': '2', 'name': 'fantasy-romance'},\n",
       "  {'count': '2', 'name': 'queue'},\n",
       "  {'count': '2', 'name': 'dragon'},\n",
       "  {'count': '1', 'name': 'favorite-must-read'},\n",
       "  {'count': '1', 'name': 'mybooks'},\n",
       "  {'count': '1', 'name': 'historical_medieval'},\n",
       "  {'count': '1', 'name': 'demons_witches_etc'},\n",
       "  {'count': '1', 'name': 'waiting-for-trade-to-mass-market'},\n",
       "  {'count': '1', 'name': 'urban-and-high-fantasy-and-scifi'},\n",
       "  {'count': '1', 'name': 'to-finish-later'},\n",
       "  {'count': '1', 'name': 'sub-genre-pnr'},\n",
       "  {'count': '1', 'name': 'kindle-unlimited-with-free-audio'},\n",
       "  {'count': '1', 'name': 'all-audiobooks'},\n",
       "  {'count': '1', 'name': 'bought-ready-to-read'},\n",
       "  {'count': '1', 'name': 'r-reread-2017'},\n",
       "  {'count': '1', 'name': 'f-ebook-kindle'},\n",
       "  {'count': '1', 'name': 'were-whatevers-shifters'},\n",
       "  {'count': '1', 'name': 'magic-y'},\n",
       "  {'count': '1', 'name': 'not-interested'},\n",
       "  {'count': '1', 'name': 'books-k'},\n",
       "  {'count': '1', 'name': 'read-books-in-a-series'},\n",
       "  {'count': '1', 'name': 'authors-c'},\n",
       "  {'count': '1', 'name': 'books-in-a-series'},\n",
       "  {'count': '1', 'name': 'read-2016'},\n",
       "  {'count': '1', 'name': 'sexy-steamy-pantie-droppin-hot'},\n",
       "  {'count': '1', 'name': 'dual-pov'},\n",
       "  {'count': '1', 'name': 'alpha'},\n",
       "  {'count': '1', 'name': 'notinterested'},\n",
       "  {'count': '1', 'name': 'romance-pnr-fr-uf-sfr-etc'},\n",
       "  {'count': '1', 'name': 'igi'},\n",
       "  {'count': '1', 'name': 'myths-and-legends'},\n",
       "  {'count': '1', 'name': 'mages-and-magic'},\n",
       "  {'count': '1', 'name': 'gr-rating-of-4-not-owned'},\n",
       "  {'count': '1', 'name': 'epub'},\n",
       "  {'count': '1', 'name': 'diane-finished'},\n",
       "  {'count': '1', 'name': 'cover_purple'},\n",
       "  {'count': '1', 'name': 'para'},\n",
       "  {'count': '1', 'name': 'hearts'},\n",
       "  {'count': '1', 'name': 'witches-fae-demons-druids-magic'},\n",
       "  {'count': '1', 'name': 'to-read-ebook-later'},\n",
       "  {'count': '1', 'name': 'epub-mp3'},\n",
       "  {'count': '1', 'name': 'free-am-un'},\n",
       "  {'count': '1', 'name': 'books-i-ve-reviewed'},\n",
       "  {'count': '1', 'name': 'on-deck'},\n",
       "  {'count': '1', 'name': 'fantasy-hot'},\n",
       "  {'count': '1', 'name': 'pov-3rd-person'},\n",
       "  {'count': '1', 'name': 'buy'},\n",
       "  {'count': '1', 'name': 'own-on-audible'},\n",
       "  {'count': '1', 'name': 'paranormal-romances'},\n",
       "  {'count': '1', 'name': 'audio-books'},\n",
       "  {'count': '1', 'name': 'pnr-challenge'},\n",
       "  {'count': '1', 'name': 'pickgenre-para'},\n",
       "  {'count': '1', 'name': 'flightsfantasy'},\n",
       "  {'count': '1', 'name': 'coyer'}],\n",
       " 'publication_day': '15',\n",
       " 'publication_month': '7',\n",
       " 'publication_year': '2014',\n",
       " 'publisher': 'Montlake Romance',\n",
       " 'ratings_count': '336',\n",
       " 'series': ['s468908'],\n",
       " 'similar_books': ['20662978',\n",
       "  '8459683',\n",
       "  '20891597',\n",
       "  '24838293',\n",
       "  '13516062',\n",
       "  '27409891',\n",
       "  '14740130',\n",
       "  '18715371',\n",
       "  '18245308',\n",
       "  '27505924',\n",
       "  '9931657',\n",
       "  '20883590',\n",
       "  '23546369',\n",
       "  '21636649',\n",
       "  '24738902'],\n",
       " 'text_reviews_count': '39',\n",
       " 'url': 'https://www.goodreads.com/book/show/17339335-knight-avenged',\n",
       " 'work_id': '24074200'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain all categories\n",
    "cats_with_counts = defaultdict(int)\n",
    "for d in whole_data:\n",
    "    for g,i in d['genre'].items():\n",
    "        cats_with_counts[g] += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_ids = set([d['book_id'] for d in whole_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiction 0.22935386545496342\n",
      "history, historical fiction, biography 0.11218489683274621\n",
      "fantasy, paranormal 0.19868476542109198\n",
      "romance 0.10883620771799321\n",
      "young-adult 0.07738126345084886\n",
      "non-fiction 0.06895897491625524\n",
      "mystery, thriller, crime 0.08572122383339018\n",
      "comics, graphic 0.058846502971987\n",
      "children 0.04873140533562655\n",
      "poetry 0.011300894065097345\n"
     ]
    }
   ],
   "source": [
    "# class distribution\n",
    "sum_cat_count = sum([k for k in cats_with_counts.values()])\n",
    "for k,v in cats_with_counts.items():\n",
    "    print(k, v/sum_cat_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_id_description = dict()\n",
    "book_id_cover = dict()\n",
    "book_id_num_pages = dict()\n",
    "book_id_rate = dict()\n",
    "book_id_similar = dict()\n",
    "book_id_shelves = dict()\n",
    "for d in whole_data:\n",
    "    b_id = d['book_id']\n",
    "    des = re.sub('<[^<]+?>', '', d['description'])\n",
    "    book_id_description[b_id] = des\n",
    "    book_id_cover[b_id] = d['cover']\n",
    "    if 'num_pages' in d:\n",
    "        book_id_num_pages[b_id] = d['num_pages']\n",
    "    if 'average_rating' and 'ratings_count' in d:\n",
    "        book_id_rate[b_id] = (d['average_rating'],d['ratings_count'])\n",
    "    book_id_similar[b_id] = set(d['similar_books']).intersection(book_ids)\n",
    "    book_id_shelves[b_id] = d['popular_shelves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = whole_data[:len(whole_data)//2]\n",
    "validation_data = whole_data[len(whole_data)//2:int(0.7*len(whole_data))]\n",
    "test_data = whole_data[int(0.7*len(whole_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "20000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(validation_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_freq(sort_genre):\n",
    "    \"\"\"\n",
    "    sort_genre: [(genre, count)]\n",
    "    \"\"\"\n",
    "    freq = sort_genre[0][1]\n",
    "    pick = []\n",
    "    for d in sort_genre:\n",
    "        if d[1] == freq:\n",
    "            pick.append(d[0])\n",
    "        else:\n",
    "            break\n",
    "    return np.random.choice(pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book_id_genre = dict()\n",
    "for d in whole_data:\n",
    "    sort_genre = sorted(d['genre'].items(),key=lambda x: x[1],reverse=True)\n",
    "    book_id_genre[d['book_id']] = most_freq(sort_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_list = list(cats_with_counts)\n",
    "genre_oh = dict()\n",
    "genre_idx = dict()\n",
    "for d in genre_list:\n",
    "    tmp = np.zeros(len(genre_list))\n",
    "    tmp[genre_list.index(d)] = 1\n",
    "    genre_oh[d] = tmp\n",
    "    genre_idx[d] = genre_list.index(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf with description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_description = []\n",
    "all_y = []\n",
    "punctuation = set(string.punctuation)\n",
    "for d in whole_data:\n",
    "    r = ''.join([c for c in book_id_description[d['book_id']].lower() if not c in punctuation])\n",
    "    all_description.append(r)\n",
    "    all_y.append(genre_idx[book_id_genre[d['book_id']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_description = []\n",
    "train_y = []\n",
    "punctuation = set(string.punctuation)\n",
    "for d in train_data:\n",
    "    r = ''.join([c for c in book_id_description[d['book_id']].lower() if not c in punctuation])\n",
    "    train_description.append(r)\n",
    "    train_y.append(genre_idx[book_id_genre[d['book_id']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_description = []\n",
    "val_y = []\n",
    "punctuation = set(string.punctuation)\n",
    "for d in validation_data:\n",
    "    r = ''.join([c for c in book_id_description[d['book_id']].lower() if not c in punctuation])\n",
    "    val_description.append(r)\n",
    "    val_y.append(genre_idx[book_id_genre[d['book_id']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_description = []\n",
    "test_y = []\n",
    "punctuation = set(string.punctuation)\n",
    "for d in test_data:\n",
    "    r = ''.join([c for c in book_id_description[d['book_id']].lower() if not c in punctuation])\n",
    "    test_description.append(r)\n",
    "    test_y.append(genre_idx[book_id_genre[d['book_id']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents='unicode',\n",
    "                             analyzer='word',\n",
    "                             lowercase=True,\n",
    "                             stop_words='english',\n",
    "                             sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mx = vectorizer.fit(all_description)\n",
    "X_train = vectorizer.transform(train_description + val_description)\n",
    "# X_val = vectorizer.transform(val_description)\n",
    "X_test = vectorizer.transform(test_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_title = []\n",
    "for d in whole_data:\n",
    "    r = ''.join([c for c in book_id_cover[d['book_id']].lower() if not c in punctuation])\n",
    "    all_title.append(r)\n",
    "    \n",
    "train_title = []\n",
    "for d in train_data:\n",
    "    r = ''.join([c for c in book_id_cover[d['book_id']].lower() if not c in punctuation])\n",
    "    train_title.append(r)\n",
    "    \n",
    "val_title = []\n",
    "for d in validation_data:\n",
    "    r = ''.join([c for c in book_id_cover[d['book_id']].lower() if not c in punctuation])\n",
    "    val_title.append(r)\n",
    "    \n",
    "test_title = []\n",
    "for d in test_data:\n",
    "    r = ''.join([c for c in book_id_cover[d['book_id']].lower() if not c in punctuation])\n",
    "    test_title.append(r)\n",
    "    \n",
    "vectorizer_title = TfidfVectorizer(strip_accents='unicode',\n",
    "                             analyzer='word',\n",
    "                             lowercase=True,\n",
    "                             stop_words='english',\n",
    "                             sublinear_tf=True)\n",
    "\n",
    "tfidf_mx_title = vectorizer_title.fit(all_title)\n",
    "title_feat_train = vectorizer_title.transform(train_title + val_title)\n",
    "# title_feat_val = vectorizer_title.transform(val_title)\n",
    "title_feat_test = vectorizer_title.transform(test_title)\n",
    "\n",
    "X_train_2 = hstack([X_train, title_feat_train])\n",
    "# X_val_2 = hstack([X_val, title_feat_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_2 = hstack([X_test, title_feat_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wts = dict()\n",
    "# for d in cats_with_counts:\n",
    "#     wts[genre_list.index(d)] = sum_cat_count / cats_with_counts[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_acc(predictions, val_y):\n",
    "    acc = sum([1 for i in range(len(predictions)) if predictions[i] == val_y[i]]) / len(predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_y = train_y + val_y\n",
    "svc = LinearSVC(C=0.1)\n",
    "svc.fit(X_train_2,all_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6788\n"
     ]
    }
   ],
   "source": [
    "predictions = svc.predict(X_test_2)\n",
    "print(get_acc(predictions,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4635.4024930000305\n",
      "0.6923666666666667\n"
     ]
    }
   ],
   "source": [
    "# feat: [description | title]\n",
    "start = time.time()\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100),learning_rate='adaptive',early_stopping=True)\n",
    "mlp.fit(X_train_2,all_train_y)\n",
    "predictions = mlp.predict(X_test_2)\n",
    "print(time.time() - start)\n",
    "print(get_acc(predictions,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cat_dict = defaultdict(str)\n",
    "t_data = train_data + validation_data\n",
    "for d in t_data:\n",
    "    cat_list = [(genre, count) for genre,count in d['genre'].items()]\n",
    "    main_cat = max(cat_list, key = lambda x: x[1])[0]\n",
    "    train_cat_dict[d['book_id']] = main_cat\n",
    "\n",
    "sim_cat_feat_train = []\n",
    "for d in train_data:\n",
    "    similar_list = book_id_similar[d['book_id']]\n",
    "    sim_cat_list = [train_cat_dict[id] for id in similar_list]\n",
    "    score_list = [0]*10\n",
    "    for cat in sim_cat_list:\n",
    "        if cat != \"\":\n",
    "            score_list[genre_idx[cat]] += 1\n",
    "    feat_arr = np.array(score_list)\n",
    "    if sum(feat_arr) != 0:\n",
    "        feat_arr = feat_arr / sum(feat_arr)\n",
    "    sim_cat_feat_train.append(feat_arr)\n",
    "    \n",
    "sim_cat_feat_val = []\n",
    "for d in validation_data:\n",
    "    similar_list = book_id_similar[d['book_id']]\n",
    "    sim_cat_list = [train_cat_dict[id] for id in similar_list]\n",
    "    score_list = [0]*10\n",
    "    for cat in sim_cat_list:\n",
    "        if cat != \"\":\n",
    "            score_list[genre_idx[cat]] += 1\n",
    "    feat_arr = np.array(score_list)\n",
    "    if sum(feat_arr) != 0:\n",
    "        feat_arr = feat_arr / sum(feat_arr)\n",
    "    sim_cat_feat_val.append(feat_arr)\n",
    "    \n",
    "X_train_3 = hstack([X_train_2, sim_cat_feat_train + sim_cat_feat_val])\n",
    "# X_val_3 = hstack([X_val_2, sim_cat_feat_val])\n",
    "\n",
    "sim_cat_feat_test = []\n",
    "for d in test_data:\n",
    "    similar_list = book_id_similar[d['book_id']]\n",
    "    sim_cat_list = [train_cat_dict[id] for id in similar_list]\n",
    "    score_list = [0]*10\n",
    "    for cat in sim_cat_list:\n",
    "        if cat != \"\":\n",
    "            score_list[genre_idx[cat]] += 1\n",
    "    feat_arr = np.array(score_list)\n",
    "    if sum(feat_arr) != 0:\n",
    "        feat_arr = feat_arr / sum(feat_arr)\n",
    "    sim_cat_feat_test.append(feat_arr)\n",
    "    \n",
    "X_test_3 = hstack([X_test_2, sim_cat_feat_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(C=0.1)\n",
    "svc.fit(X_train_3,all_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7068\n"
     ]
    }
   ],
   "source": [
    "predictions = svc.predict(X_test_3)\n",
    "print(get_acc(predictions,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_train = train_data + validation_data\n",
    "rate_count_feat_train = np.log(np.array([np.max([int(d['ratings_count']), 0.1]) for d in t_train]))\n",
    "rate_count_mean = np.mean(rate_count_feat_train)\n",
    "rate_count_std = np.std(rate_count_feat_train)\n",
    "rate_count_feat_train = (rate_count_feat_train - rate_count_mean) / (3 * rate_count_std)\n",
    "rate_count_feat_train = np.reshape(rate_count_feat_train, (len(rate_count_feat_train), 1))\n",
    "\n",
    "# rate_count_feat_val = np.log(np.array([np.max([int(d['ratings_count']), 0.1]) for d in validation_data]))\n",
    "# rate_count_mean = np.mean(rate_count_feat_val)\n",
    "# rate_count_std = np.std(rate_count_feat_val)\n",
    "# rate_count_feat_val = (rate_count_feat_val - rate_count_mean) / (3 * rate_count_std)\n",
    "# rate_count_feat_val = np.reshape(rate_count_feat_val, (len(rate_count_feat_val), 1))\n",
    "\n",
    "X_train_4 = hstack([X_train_3, rate_count_feat_train])\n",
    "# X_val_4 = hstack([X_val_3, rate_count_feat_val])\n",
    "\n",
    "rate_count_feat_test = np.log(np.array([np.max([int(d['ratings_count']), 0.1]) for d in test_data]))\n",
    "rate_count_mean = np.mean(rate_count_feat_test)\n",
    "rate_count_std = np.std(rate_count_feat_test)\n",
    "rate_count_feat_test = (rate_count_feat_test - rate_count_mean) / (3 * rate_count_std)\n",
    "rate_count_feat_test = np.reshape(rate_count_feat_test, (len(rate_count_feat_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_4 = hstack([X_test_3, rate_count_feat_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(C=0.1)\n",
    "svc.fit(X_train_4,all_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7074333333333334\n"
     ]
    }
   ],
   "source": [
    "predictions = svc.predict(X_test_4)\n",
    "print(get_acc(predictions,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-613335cb8eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflattened_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mflattened_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflattened_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflattened_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflattened_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1357\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1040\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1041\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "flattened_test = np.array(test_y).reshape(1,np.array(test_y).shape[0])[0]\n",
    "flattened_pred = np.array(predictions).reshape(1,np.array(predictions).shape[0])[0]\n",
    "print(recall_score(flattened_test,flattened_pred))\n",
    "print(precision_score(flattened_test,flattened_pred))\n",
    "print(f1_score(flattened_test,flattened_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4796.206936836243\n",
      "0.7165666666666667\n"
     ]
    }
   ],
   "source": [
    "# feat: [description | title | similar books | rating counts]\n",
    "start = time.time()\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100),learning_rate='adaptive',early_stopping=True)\n",
    "mlp.fit(X_train_4,all_train_y)\n",
    "predictions = mlp.predict(X_test_4)\n",
    "print(time.time() - start)\n",
    "print(get_acc(predictions,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilable attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilabel_convert(genres):\n",
    "    tmp = np.zeros(len(genre_list))\n",
    "    for g in genres:\n",
    "        tmp[genre_list.index(g)] = 1\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_book_to_genre_oh = dict()\n",
    "for d in whole_data:\n",
    "    multi_book_to_genre_oh[d['book_id']] = multilabel_convert(list(d['genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_train_y = []\n",
    "punctuation = set(string.punctuation)\n",
    "for d in train_data:\n",
    "    mul_train_y.append(multi_book_to_genre_oh[d['book_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_val_y = []\n",
    "punctuation = set(string.punctuation)\n",
    "for d in validation_data:\n",
    "    mul_val_y.append(multi_book_to_genre_oh[d['book_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mul_test_y = []\n",
    "punctuation = set(string.punctuation)\n",
    "for d in test_data:\n",
    "    mul_test_y.append(multi_book_to_genre_oh[d['book_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mul_train_y = mul_train_y + mul_val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402.39863777160645\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_4,all_mul_train_y)\n",
    "predictions = clf.predict(X_test_4)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "total = 0\n",
    "for i,p in enumerate(predictions):\n",
    "    teacher = mul_test_y[i]\n",
    "    for j,d in enumerate(p):\n",
    "        if teacher[j] == d:\n",
    "            acc += 1\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288633333333333"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.407394498365\n",
      "0.809860093271\n",
      "0.542092917473\n"
     ]
    }
   ],
   "source": [
    "flattened_test = np.array(mul_test_y).reshape(1,np.array(mul_test_y).shape[0]*np.array(mul_test_y).shape[1])[0]\n",
    "flattened_pred = np.array(predictions).reshape(1,np.array(predictions).shape[0]*np.array(predictions).shape[1])[0]\n",
    "print(recall_score(flattened_test,flattened_pred))\n",
    "print(precision_score(flattened_test,flattened_pred))\n",
    "print(f1_score(flattened_test,flattened_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.363218064621\n",
      "0.761053302187\n",
      "0.491746593669\n"
     ]
    }
   ],
   "source": [
    "# previous value from pure description\n",
    "# flattened_test = np.array(mul_test_y).reshape(1,np.array(mul_test_y).shape[0]*np.array(mul_test_y).shape[1])[0]\n",
    "# flattened_pred = np.array(predictions).reshape(1,np.array(predictions).shape[0]*np.array(predictions).shape[1])[0]\n",
    "# print(recall_score(flattened_test,flattened_pred))\n",
    "# print(precision_score(flattened_test,flattened_pred))\n",
    "# print(f1_score(flattened_test,flattened_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# previous_w_des_acc = 81.4795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300.544007062912\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100),learning_rate='adaptive',early_stopping=True)\n",
    "mlp.fit(X_train_4,all_mul_train_y)\n",
    "predictions = mlp.predict(X_test_4)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "total = 0\n",
    "for i,p in enumerate(predictions):\n",
    "    teacher = mul_test_y[i]\n",
    "    for j,d in enumerate(p):\n",
    "        if teacher[j] == d:\n",
    "            acc += 1\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88476"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69283875811\n",
      "0.81593571406\n",
      "0.749365657034\n"
     ]
    }
   ],
   "source": [
    "flattened_test = np.array(mul_test_y).reshape(1,np.array(mul_test_y).shape[0]*np.array(mul_test_y).shape[1])[0]\n",
    "flattened_pred = np.array(predictions).reshape(1,np.array(predictions).shape[0]*np.array(predictions).shape[1])[0]\n",
    "print(recall_score(flattened_test,flattened_pred))\n",
    "print(precision_score(flattened_test,flattened_pred))\n",
    "print(f1_score(flattened_test,flattened_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.633923865894\n",
      "0.800911698422\n",
      "0.707700663031\n"
     ]
    }
   ],
   "source": [
    "# previous mlp only description\n",
    "# acc = 87.083\n",
    "# flattened_val = np.array(mul_val_y).reshape(1,np.array(mul_val_y).shape[0]*np.array(mul_val_y).shape[1])[0]\n",
    "# flattened_pred = np.array(predictions).reshape(1,np.array(predictions).shape[0]*np.array(predictions).shape[1])[0]\n",
    "# print(recall_score(flattened_val,flattened_pred))\n",
    "# print(precision_score(flattened_val,flattened_pred))\n",
    "# print(f1_score(flattened_val,flattened_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
